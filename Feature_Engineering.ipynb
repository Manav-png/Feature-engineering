{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***Feature Engineering***\n",
        "\n",
        "---\n",
        "\n",
        "###1) What is a parameter?\n",
        "\n",
        "->\n",
        "\n",
        "A parameter is a variable used in a function to accept input values (called arguments) when the function is called.\n",
        "\n",
        "---\n",
        "\n",
        "###2) What is correlation? What does negative correlation mean?\n",
        "\n",
        "->\n",
        "\n",
        "***Correlation is a statistical measure that shows how two variables move in relation to each other.***\n",
        "\n",
        "* If one increases and the other also increases → Positive correlation\n",
        "\n",
        "* If one increases and the other decreases → Negative correlation\n",
        "\n",
        "* If there's no clear pattern → No correlation\n",
        "\n",
        "***What does Negative Correlation Mean?***\n",
        "\n",
        "A negative correlation means that as one variable increases, the other decreases.\n",
        "\n",
        "***Example:***\n",
        "As the number of hours you watch TV increases, your exam score might decrease → negative correlation.\n",
        "\n",
        "---\n",
        "\n",
        "###3) Define Machine Learning. What are the main components in Machine Learning?\n",
        "\n",
        "->\n",
        "\n",
        "***Definition of Machine Learning:***\n",
        "\n",
        "Machine Learning (ML) is a branch of Artificial Intelligence (AI) that enables systems to learn from data, improve performance over time, and make decisions without being explicitly programmed.\n",
        "\n",
        "***Main Components of Machine Learning:***\n",
        "\n",
        "    Data\n",
        "\n",
        "* Raw information used to train and test the model.\n",
        "\n",
        "* The quality and quantity of data greatly affect performance.\n",
        "\n",
        "  \n",
        "    Model\n",
        "\n",
        "* The algorithm or mathematical structure that makes predictions or decisions.\n",
        "\n",
        "* Example: Linear Regression, Decision Trees, Neural Networks.\n",
        "\n",
        "\n",
        "    Features\n",
        "\n",
        "* The input variables used to make predictions.\n",
        "\n",
        "* Example: Age, Income, and Education level in a loan prediction system.\n",
        "\n",
        "\n",
        "    Training\n",
        "\n",
        "* The process of feeding data to the model so it can learn patterns.\n",
        "\n",
        "\n",
        "    Evaluation\n",
        "\n",
        "* Testing the model’s performance using unseen data.\n",
        "\n",
        "* Metrics: Accuracy, Precision, Recall, etc.\n",
        "\n",
        "\n",
        "    Prediction\n",
        "\n",
        "* Using the trained model to make decisions or forecast outcomes on new data.\n",
        "\n",
        "\n",
        "    Feedback Loop (optional)\n",
        "\n",
        "* Improves the model over time by learning from new data or correcting mistakes.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "###4) How does loss value help in determining whether the model is good or not?\n",
        "\n",
        "->\n",
        "\n",
        "* The loss value is a key indicator of how well a machine learning model is performing.\n",
        "* It represents the difference between the model’s predicted output and the actual target values.\n",
        "* A low loss means the model's predictions are close to the real values, indicating good performance.\n",
        "* On the other hand, a high loss suggests poor predictions and that the model needs improvement.\n",
        "* During training, the model learns by trying to minimize this loss, which helps it make better predictions over time.\n",
        "* Therefore, monitoring the loss value helps determine whether the model is improving and whether it is suitable for making accurate predictions.\n",
        "\n",
        "---\n",
        "\n",
        "###5) What are continuous and categorical variables?\n",
        "\n",
        "->\n",
        "\n",
        "**Continuous Variables** are numerical values that can take any value within a range. They are measurable and often include decimals.\n",
        "    \n",
        "    Examples: Height, Weight, Temperature, Income.\n",
        "\n",
        "**Categorical Variables** are variables that represent categories or groups. They are not measured but classified.\n",
        "\n",
        "    Examples: Gender (Male/Female), Color (Red/Blue/Green), Country.\n",
        "\n",
        "---\n",
        "\n",
        "###6) How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "\n",
        "->\n",
        "\n",
        "To handle categorical variables in machine learning, we convert them into numbers using encoding techniques.\n",
        "\n",
        "***Common techniques:***\n",
        "\n",
        "* Label Encoding: Assigns each category a number.\n",
        "\n",
        "* One-Hot Encoding: Creates separate binary columns for each category.\n",
        "\n",
        "* Ordinal Encoding: Numbers categories based on order.\n",
        "\n",
        "These help models understand and use categorical data effectively.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "###7) What do you mean by training and testing a dataset?\n",
        "\n",
        "->\n",
        "\n",
        "* Training and testing a dataset refers to splitting the data into two parts to build and evaluate a machine learning model.\n",
        "\n",
        "\n",
        "    Training Dataset:\n",
        "\n",
        "Used to train the model so it can learn patterns from the data.\n",
        "\n",
        "\n",
        "    Testing Dataset:\n",
        "\n",
        "Used to evaluate the model's performance on unseen data to check how well it generalizes.\n",
        "\n",
        "**In short:**\n",
        "\n",
        "**Training**= Learning phase\n",
        "\n",
        "**Testing** = Performance check\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "###8) What is sklearn.preprocessing?\n",
        "\n",
        "->\n",
        "\n",
        "* `**sklearn.preprocessing**` is a module in scikit-learn that helps in transforming and scaling data before feeding it to machine learning models.\n",
        "* It includes tools like **StandardScaler** (for standardizing data), **MinMaxScaler** (for scaling features), **LabelEncoder** (for encoding categorical labels), and **OneHotEncoder** (for converting categorical features into binary columns).\n",
        "* These techniques improve model performance and make data ready for algorithms.\n",
        "\n",
        "---\n",
        "\n",
        "###9) What is a Test set?\n",
        "\n",
        "->\n",
        "\n",
        "* A test set is a portion of the dataset that is used to evaluate the performance of a trained machine learning model.\n",
        "* It consists of data that the model has never seen during training, allowing you to assess how well the model generalizes to new, unseen data.\n",
        "\n",
        "* In practice, the dataset is usually split into:\n",
        "\n",
        "* **Training set**: Used to train the model.\n",
        "\n",
        "* **Test set**: Used to test the model's accuracy and performance.\n",
        "\n",
        "* The test set helps you understand if the model is overfitting or underfitting and gives you an idea of its real-world performance.\n",
        "\n",
        "---\n",
        "\n",
        "###10) How do we split data for model fitting (training and testing) in Python? How do you approach a Machine Learning problem?\n",
        "\n",
        "->\n",
        "\n",
        "    Splitting Data in Python:\n",
        "\n",
        "Use train_test_split from scikit-learn to split data into training and test sets.\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "    Approaching a Machine Learning Problem:\n",
        "* Define the problem (classification, regression, etc.).\n",
        "\n",
        "* Collect and clean data (handle missing values, outliers).\n",
        "\n",
        "* Explore the data (visualize patterns, correlations).\n",
        "\n",
        "* Preprocess the data (encode categorical features, scale numerical features).\n",
        "\n",
        "* Choose a model (start simple, then test complex models).\n",
        "\n",
        "* Train the model on the training data.\n",
        "\n",
        "* Evaluate the model using the test set.\n",
        "\n",
        "* Tune hyperparameters for optimization.\n",
        "\n",
        "* Deploy the model if necessary.\n",
        "\n",
        "* Monitor and update the model over time.\n",
        "\n",
        "---\n",
        "\n",
        "###11) Why do we have to perform EDA before fitting a model to the data?\n",
        "\n",
        "->\n",
        "\n",
        "Exploratory Data Analysis (EDA) is crucial before fitting a model because it helps you understand your data and make informed decisions during the model-building process.\n",
        "\n",
        "**Here's why it's important:**\n",
        "\n",
        "    Understand Data Distribution:\n",
        "\n",
        "EDA helps identify the distribution of features (e.g., normal, skewed) so you can choose the appropriate model and preprocessing steps.\n",
        "\n",
        "    Detect Missing or Outlier Values:\n",
        "\n",
        "It helps identify missing values, outliers, or errors in the data, which you can handle before model training.\n",
        "\n",
        "    Understand Relationships Between Features:\n",
        "\n",
        "By visualizing correlations and interactions, you can identify which features are important for prediction and which can be dropped.\n",
        "\n",
        "    Feature Engineering:\n",
        "\n",
        "EDA provides insights that help you create new features or transform existing ones to improve model performance.\n",
        "\n",
        "    Avoid Overfitting/Underfitting:\n",
        "\n",
        "By exploring the data, you can detect if some features may cause overfitting or if you need to engineer better features to prevent underfitting.\n",
        "\n",
        "    Determine Data Types:\n",
        "\n",
        "Helps identify categorical and numerical variables, so you can apply the right encoding or scaling techniques.\n",
        "\n",
        "---\n",
        "\n",
        "###12) What is correlation?\n",
        "\n",
        "->\n",
        "\n",
        "* Correlation is a statistical measure that describes the relationship between two variables. It indicates how one variable changes in relation to another.\n",
        "\n",
        "* **Positive Correlation**: When one variable increases, the other also increases.\n",
        "\n",
        "* **Negative Correlation**: When one variable increases, the other decreases.\n",
        "\n",
        "* **No Correlation**: No clear relationship between the two variables.\n",
        "\n",
        "* Correlation is measured using a coefficient, commonly the Pearson correlation coefficient, which ranges from:\n",
        "\n",
        "  * +1: Perfect positive correlation (both variables increase together).\n",
        "\n",
        "  * -1: Perfect negative correlation (one variable increases, the other decreases).\n",
        "\n",
        "  * 0: No correlation (the variables are unrelated).\n",
        "\n",
        "---\n",
        "\n",
        "###13) What does negative correlation mean?\n",
        "\n",
        "->\n",
        "\n",
        "* Negative correlation means that as one variable increases, the other variable decreases. In other words, they move in opposite directions.\n",
        "\n",
        "**Example:**\n",
        "As the temperature increases, the amount of clothing worn might decrease (people wear lighter clothes in warmer weather).\n",
        "\n",
        "* As study time increases, errors in the exam might decrease (more study could lead to fewer mistakes).\n",
        "\n",
        "* A negative correlation is represented by a correlation coefficient between -1 and 0. The closer it is to -1, the stronger the negative relationship.\n",
        "\n",
        "---\n",
        "\n",
        "###14) How can you find correlation between variables in Python?\n",
        "\n",
        "->\n",
        "\n",
        "* In Python, you can use **pandas** to find the correlation between variables using the **`corr()`** function, which computes the correlation matrix for numerical columns in a DataFrame.\n",
        "* For example, after loading your dataset into a pandas DataFrame, calling `df.corr()` will return a matrix showing the pairwise correlation between the columns.\n",
        "* A correlation of **1** indicates perfect positive correlation, **-1** indicates perfect negative correlation, and **0** indicates no correlation.\n",
        "* This method helps you understand the linear relationships between variables.\n",
        "* For a more visual representation, you can use libraries like **seaborn** to plot a **heatmap** of the correlation matrix.\n",
        "\n",
        "---\n",
        "\n",
        "###15) What is causation? Explain difference between correlation and causation with an example.\n",
        "\n",
        "->\n",
        "\n",
        "    Causation:\n",
        "Causation refers to a cause-and-effect relationship where one variable directly influences or brings about a change in another variable. In other words, a change in one variable causes a change in the other.\n",
        "\n",
        "    Difference Between Correlation and Causation:\n",
        "* Correlation means two variables are related or move together in some way, but it doesn't imply one causes the other.\n",
        "\n",
        "* Causation means that one variable directly causes the other to change.\n",
        "\n",
        "\n",
        "    Example:\n",
        "\n",
        "**Correlation:**\n",
        "* There may be a positive correlation between the number of ice creams sold and the number of people who drown at the beach. When more ice cream is sold, more people may drown.\n",
        "* But this does not mean ice cream sales cause drowning. Instead, both are influenced by a third factor: warm weather.\n",
        "\n",
        "**Causation:**\n",
        "* If you study hard, you may cause your exam scores to improve. Here, the effort (studying) directly impacts the outcome (exam score), showing causation.\n",
        "\n",
        "  \n",
        "    Key Difference:\n",
        "\n",
        "* Correlation is about relationships between variables.\n",
        "\n",
        "* Causation is about direct cause-and-effect relationships.\n",
        "\n",
        "----\n",
        "\n",
        "###16) What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "\n",
        "->\n",
        "\n",
        "An optimizer in machine learning adjusts the model's weights to minimize the loss function and improve accuracy.\n",
        "\n",
        "    Common Optimizers:\n",
        "* ***Gradient Descent (GD)***: Updates weights using the entire dataset’s gradient.\n",
        "\n",
        "* ***Stochastic Gradient Descent (SGD)***: Uses a single data point to update weights, faster but noisier.\n",
        "\n",
        "* ***Mini-Batch Gradient Descent***: Uses a small subset of the data to balance speed and stability.\n",
        "\n",
        "* ***Momentum***: Adds the previous update to the current one, speeding up convergence and reducing oscillations.\n",
        "\n",
        "* ***Adam***: Combines Momentum and RMSProp, adapts learning rates, and works well in practice.\n",
        "\n",
        "* ***RMSProp***: Adjusts learning rates based on recent gradients, useful for non-stationary problems.\n",
        "\n",
        "---\n",
        "\n",
        "###17) What is sklearn.linear_model ?\n",
        "\n",
        "->\n",
        "\n",
        "* **`sklearn.linear_model`** is a module in **scikit-learn** that provides algorithms for **linear models**, which are used for both **regression** and **classification** tasks.\n",
        "* It includes models like **LinearRegression** for predicting continuous values, **LogisticRegression** for binary classification, and regularized models such as **Ridge** and **Lasso** regression, which add **L2** and **L1** regularization respectively to prevent overfitting.\n",
        "* **ElasticNet** combines both L1 and L2 regularization. The module also includes **SGDClassifier** and **SGDRegressor**, which use **stochastic gradient descent (SGD)** for more efficient training on large datasets, and **Perceptron**, a simple neural network model for classification.\n",
        "* These linear models are crucial in machine learning, offering a strong foundation for understanding relationships between features and outcomes.\n",
        "\n",
        "---\n",
        "\n",
        "###18) What does model.fit() do? What arguments must be given?\n",
        "\n",
        "->\n",
        "\n",
        "The model.fit() method in machine learning is used to train a model on the provided dataset.\n",
        "\n",
        " It takes two main arguments:\n",
        "\n",
        "* X (features): A 2D array of input data (shape: (n_samples, n_features)).\n",
        "\n",
        "* y (target): A 1D array of target values or labels.\n",
        "\n",
        "For example, model.fit(X, y) adjusts the model's parameters to learn the relationship between X and y.\n",
        "\n",
        "---\n",
        "\n",
        "###19) What does model.predict() do? What arguments must be given?\n",
        "\n",
        "->\n",
        "\n",
        "* The **`model.predict()`** method is used to generate **predictions** based on the data after a model has been trained with the **`fit()`** method.\n",
        "* It takes a **2D array** (or DataFrame) of input features, **X**, which represents the new, unseen data for which predictions are required.\n",
        "* The shape of **X** should be `(n_samples, n_features)`, where `n_samples` is the number of new data points and `n_features` is the number of features for each data point. Once you provide the new data, **`model.predict(X)`** returns the predicted values or labels based on the trained model.\n",
        "* For example, in regression tasks, it would output predicted continuous values for the given input.\n",
        "\n",
        "---\n",
        "\n",
        "###20) What are continuous and categorical variables?\n",
        "\n",
        "->\n",
        "\n",
        "Continuous Variables and Categorical Variables are two types of variables used in data analysis and machine learning.\n",
        "\n",
        "\n",
        "    Continuous Variables:\n",
        "* These are numerical variables that can take any value within a certain range and can be measured with high precision.\n",
        "\n",
        "* They can have infinite possible values and are typically represented by real numbers.\n",
        "\n",
        "* Examples: Height, weight, temperature, age, income, etc.\n",
        "\n",
        "* Continuous variables can be quantitative and are often used in regression models.\n",
        "\n",
        "  \n",
        "    Categorical Variables:\n",
        "\n",
        "* These are variables that take on discrete values, which represent categories or groups.\n",
        "\n",
        "* The values are usually non-numeric, although they can be encoded as numbers (e.g., 1 for Male, 2 for Female).\n",
        "\n",
        "* Examples: Gender, color, city, country, type of product, etc.\n",
        "\n",
        "* Categorical variables are often used in classification models and can be either nominal (no inherent order, like colors) or ordinal (have a meaningful order, like educational level).\n",
        "\n",
        "    \n",
        "    Summary:\n",
        "\n",
        "* Continuous variables represent measurable quantities that can take any value (e.g., height, temperature).\n",
        "\n",
        "* Categorical variables represent categories or groups and have limited distinct values (e.g., color, gender).\n",
        "\n",
        "---\n",
        "\n",
        "###21) What is feature scaling? How does it help in Machine Learning?\n",
        "\n",
        "->\n",
        "\n",
        "* **Feature scaling** is the process of standardizing or normalizing the range of features in a dataset. It ensures all features contribute equally to the model, especially when they are on different scales or units.\n",
        "\n",
        "- **Normalization** (Min-Max Scaling) rescales data to a fixed range, usually [0, 1].\n",
        "- **Standardization** (Z-score Normalization) rescales data to have a mean of 0 and a standard deviation of 1.\n",
        "\n",
        "Feature scaling helps improve model performance, speeds up convergence, and prevents bias in algorithms like **KNN**, **SVM**, and **Gradient Descent-based models**.\n",
        "\n",
        "---\n",
        "\n",
        "###22) How do we perform scaling in Python?\n",
        "\n",
        "->\n",
        "\n",
        "* In Python, feature scaling can be performed using **scikit-learn**.\n",
        "* For **Normalization (Min-Max Scaling)**, you can use `MinMaxScaler` to scale data to a range of [0, 1].\n",
        "* For **Standardization (Z-score Normalization)**, `StandardScaler` is used to scale data so that it has a mean of 0 and a standard deviation of 1.\n",
        "* Both methods can be applied using the `fit_transform()` method, which fits the scaler to the data and transforms it into the scaled version, improving the model's performance and convergence speed.\n",
        "\n",
        "---\n",
        "\n",
        "###23) What is sklearn.preprocessing?\n",
        "\n",
        "->\n",
        "\n",
        "* **`sklearn.preprocessing`** is a module in **scikit-learn** that provides tools for preparing data for machine learning.\n",
        "* It includes methods for **scaling** (like `StandardScaler` and `MinMaxScaler`), **encoding** categorical variables (e.g., `OneHotEncoder`, `LabelEncoder`), generating **polynomial features**, and handling **outliers** (e.g., `RobustScaler`).\n",
        "* These techniques ensure the data is in an optimal format for model training, improving accuracy and performance.\n",
        "\n",
        "---\n",
        "\n",
        "###24) How do we split data for model fitting (training and testing) in Python?\n",
        "\n",
        "->\n",
        "\n",
        "* In Python, data can be split into **training** and **testing** sets using the `train_test_split` function from **scikit-learn's `model_selection`** module.\n",
        "* This function randomly divides the dataset into two subsets: one for training the model and one for testing its performance.\n",
        "* The function takes the features (X) and target (y) as input, along with the proportion of data to be used for testing (using the `test_size` parameter, e.g., 0.2 for 20% testing and 80% training). By setting the `random_state` parameter, you can ensure the split is reproducible.\n",
        "* This method helps evaluate a model’s performance on unseen data and prevents overfitting.\n",
        "\n",
        "---\n",
        "\n",
        "###25) Explain data encoding?\n",
        "\n",
        "->\n",
        "\n",
        "**Data encoding** is the process of converting **categorical data** into a numerical format for machine learning algorithms. Common techniques include:\n",
        "\n",
        "1. **Label Encoding**: Assigns a unique number to each category (useful for ordinal data).\n",
        "2. **One-Hot Encoding**: Creates binary columns for each category (ideal for nominal data).\n",
        "3. **Binary Encoding**: Converts categories into binary form, useful for high-cardinality features.\n",
        "4. **Target Encoding**: Replaces categories with the mean of the target variable.\n",
        "\n",
        "These methods make categorical data usable in machine learning models.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "BXp-Mh_HW7Er"
      }
    }
  ]
}